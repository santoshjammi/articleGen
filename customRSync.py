import os
import ftplib
import concurrent.futures
import json
import time
import logging
from datetime import datetime
from tqdm import tqdm
from dotenv import load_dotenv

# IMPORTANT: You will need to install the required libraries.
# Run this command in your terminal:
# pip install tqdm python-dotenv

# --- Configuration and Environment Variables ---
# Load environment variables from the .env file
load_dotenv()

# Setup logging - FILE ONLY for performance
log_dir = "logs"
os.makedirs(log_dir, exist_ok=True)
log_filename = f"{log_dir}/customRSync_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_filename)
        # Removed StreamHandler for performance
    ]
)
logger = logging.getLogger(__name__)

# Get the FTP credentials and paths from environment variables
FTP_HOST = os.getenv("FTP_HOST")
FTP_USER = os.getenv("FTP_USER")
FTP_PASS = os.getenv("FTP_PASS")
LOCAL_DIRECTORY = os.getenv("LOCAL_DIRECTORY")
REMOTE_DIRECTORY = os.getenv("REMOTE_DIRECTORY")
MAX_WORKERS = int(os.getenv("MAX_WORKERS", 16)) # Increased default for better performance

# Manifest file path to store uploaded file details
MANIFEST_FILE_PATH = os.path.join(LOCAL_DIRECTORY, ".sync_manifest.json")

# --- Helper Function to verify remote directory structure ---
def verify_remote_directory(remote_dir, ftp_credentials):
    """
    Connects to FTP server and verifies the remote directory structure.
    Returns True if the remote directory contains expected subdirectories.
    """
    host, user, password = ftp_credentials
    try:
        with ftplib.FTP(host) as ftp:
            ftp.login(user=user, passwd=password)
            ftp.cwd(remote_dir)
            
            # Check for expected directories
            dir_list = ftp.nlst()
            expected_dirs = ["articles", "categories", "images"]
            found_dirs = [d for d in expected_dirs if d in dir_list]
            
            if len(found_dirs) >= 2:  # At least 2 of 3 expected directories
                logger.info(f"‚úÖ Remote verification successful: {found_dirs}")
                return True
            else:
                logger.error(f"‚ùå Remote verification failed: missing expected directories")
                return False
                
    except Exception as e:
        logger.error(f"‚ùå Remote verification failed: {e}")
        return False

# --- Helper Function to load the manifest ---
def load_manifest():
    """Loads the manifest from a local file (generated by auto_publish.sh)."""
    logger.info("Loading sync manifest generated by auto_publish.sh...")
    if os.path.exists(MANIFEST_FILE_PATH):
        with open(MANIFEST_FILE_PATH, 'r') as f:
            try:
                manifest = json.load(f)
                logger.info(f"Manifest loaded successfully with {len(manifest)} entries")
                return manifest
            except json.JSONDecodeError:
                logger.warning("Manifest file is corrupted or empty. Starting with an empty manifest.")
                return {}
    logger.error("Manifest file not found. Please ensure auto_publish.sh has run generateLocalManifest.py first.")
    return {}

# --- Helper Function for Uploading a Single File (Optimized) ---
def upload_file(local_path, remote_path, ftp_credentials):
    """
    Connects to the FTP server and uploads a single file.
    Returns (success_status, file_size) for manifest updating.
    """
    host, user, password = ftp_credentials
    try:
        # Create a new FTP connection for this thread
        with ftplib.FTP(host) as ftp:
            ftp.login(user=user, passwd=password)
            with open(local_path, 'rb') as file:
                ftp.storbinary(f'STOR {remote_path}', file)
            # Return success and file size for manifest update
            return True, os.path.getsize(local_path)
    except Exception:
        return False, 0

# --- Helper Function to update manifest ---
def update_manifest(uploaded_files):
    """Updates the manifest with successfully uploaded files"""
    if not uploaded_files:
        return
    
    # Load current manifest
    manifest = load_manifest()
    
    # Update with new files
    for remote_path, file_size in uploaded_files.items():
        manifest[remote_path] = file_size
    
    # Save updated manifest
    try:
        with open(MANIFEST_FILE_PATH, 'w') as f:
            json.dump(manifest, f, indent=2)
        logger.info(f"‚úÖ Manifest updated with {len(uploaded_files)} files")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Warning: Could not update manifest: {e}")

# --- Main Parallel Upload Function ---
def upload_folder_parallel(local_dir, remote_dir, max_workers):
    """
    Synchronizes a local directory to a remote FTP server in parallel,
    using a pre-generated local manifest.
    """
    sync_start = time.time()
    logger.info("Starting FTP synchronization process...")
    
    if not all([FTP_HOST, FTP_USER, FTP_PASS, local_dir, remote_dir]):
        logger.error("One or more required environment variables are not set. Please check your .env file.")
        return

    ftp_credentials = (FTP_HOST, FTP_USER, FTP_PASS)
    
    # Verify remote directory structure before proceeding
    logger.info("üöÄ Starting FTP Sync with Remote Verification")
    logger.info("=" * 50)
    
    verify_start = time.time()
    if not verify_remote_directory(remote_dir, ftp_credentials):
        logger.error("‚ùå Remote verification failed. Sync aborted.")
        return
    verify_time = time.time() - verify_start
    logger.info(f"‚úÖ Remote verification completed in {verify_time:.2f} seconds")
    
    # Load the manifest (represents current remote state)
    manifest_start = time.time()
    remote_files = load_manifest()
    manifest_time = time.time() - manifest_start
    logger.info(f"Manifest processing completed in {manifest_time:.2f} seconds")
    
    if not remote_files:
        logger.warning("‚ö†Ô∏è Warning: Manifest is empty. This will upload all files.")
        # Remove interactive prompt for automation
        logger.info("Proceeding with full upload...")
    
    files_to_upload = []
    
    # Collect all directories and files for processing
    directories_to_create = set()
    
    # Walk through the local directory to find all files and folders
    for root, dirs, files in os.walk(local_dir):
        # Collect directories for batch creation
        for dir_name in dirs:
            local_subdir = os.path.join(root, dir_name)
            remote_subdir = os.path.join(remote_dir, os.path.relpath(local_subdir, local_dir)).replace("\\", "/")
            directories_to_create.add(remote_subdir)

        # Determine which files need to be uploaded
        for file_name in files:
            local_path = os.path.join(root, file_name)
            relative_path = os.path.relpath(local_path, local_dir)
            remote_path = os.path.join(remote_dir, relative_path).replace("\\", "/")
            local_size = os.path.getsize(local_path)
            
            # Check if the file exists in the manifest and if its size is different
            if remote_path not in remote_files or remote_files[remote_path] != local_size:
                files_to_upload.append((local_path, remote_path))
    
    # Create directories in batch (silently)
    if directories_to_create:
        try:
            with ftplib.FTP(FTP_HOST) as ftp:
                ftp.login(user=FTP_USER, passwd=FTP_PASS)
                for remote_dir_path in sorted(directories_to_create):
                    try:
                        ftp.mkd(remote_dir_path)
                    except ftplib.error_perm:
                        # Directory already exists, continue silently
                        pass
        except Exception:
            # Silently continue if directory creation fails
            pass

    logger.info(f"üöÄ Starting parallel upload with {max_workers} workers...")
    upload_start = time.time()

    # Use ThreadPoolExecutor for maximum parallel performance
    successful_uploads = 0
    failed_uploads = 0
    uploaded_files = {}  # Track successfully uploaded files for manifest update
    total_bytes = 0
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # Submit all uploads at once for maximum parallelism
        future_to_file = {
            executor.submit(upload_file, local_path, remote_path, ftp_credentials): (local_path, remote_path)
            for local_path, remote_path in files_to_upload
        }

        # Process results with minimal overhead
        for future in tqdm(concurrent.futures.as_completed(future_to_file), 
                          total=len(files_to_upload), 
                          desc="Uploading",
                          ncols=80,
                          unit="files"):
            local_path, remote_path = future_to_file[future]
            success, file_size = future.result()
            if success:
                successful_uploads += 1
                uploaded_files[remote_path] = file_size
                total_bytes += file_size
                logger.debug(f"‚úÖ Uploaded: {os.path.basename(remote_path)} ({file_size} bytes)")
            else:
                failed_uploads += 1
                logger.warning(f"‚ùå Failed: {os.path.basename(remote_path)}")

    upload_time = time.time() - upload_start
    sync_time = time.time() - sync_start
    
    # Log comprehensive results
    logger.info("=" * 60)
    logger.info("UPLOAD SUMMARY")
    logger.info("=" * 60)
    logger.info(f"üìä Files processed: {len(files_to_upload)}")
    logger.info(f"‚úÖ Successful uploads: {successful_uploads}")
    logger.info(f"‚ùå Failed uploads: {failed_uploads}")
    logger.info(f"üìà Total data uploaded: {total_bytes:,} bytes ({total_bytes/1024/1024:.2f} MB)")
    logger.info(f"‚è±Ô∏è Upload time: {upload_time:.2f} seconds")
    logger.info(f"‚ö° Upload speed: {(total_bytes/upload_time/1024/1024):.2f} MB/s" if upload_time > 0 else "N/A")
    logger.info(f"üïí Total sync time: {sync_time:.2f} seconds")
    
    # Update manifest with successfully uploaded files
    if uploaded_files:
        manifest_update_start = time.time()
        update_manifest(uploaded_files)
        manifest_update_time = time.time() - manifest_update_start
        logger.info(f"üìù Manifest updated in {manifest_update_time:.2f} seconds")

# --- Main execution block ---
if __name__ == "__main__":
    start_time = time.time()
    print(f"üöÄ Custom FTP Sync (uses manifest from auto_publish.sh) - Log: {log_filename}")
    
    logger.info("=" * 60)
    logger.info("Starting Custom FTP Sync Operation")
    logger.info("=" * 60)
    logger.info("NOTE: Using manifest generated by auto_publish.sh Step 0")
    logger.info(f"Log file: {log_filename}")
    logger.info(f"Local Directory: {LOCAL_DIRECTORY}")
    logger.info(f"Remote Directory: {REMOTE_DIRECTORY}")
    logger.info(f"Max Workers: {MAX_WORKERS}")
    logger.info(f"FTP Host: {FTP_HOST}")
    
    try:
        upload_folder_parallel(LOCAL_DIRECTORY, REMOTE_DIRECTORY, MAX_WORKERS)
        
        end_time = time.time()
        total_time = end_time - start_time
        print(f"‚úÖ Sync completed in {total_time:.1f}s")
        
        logger.info("=" * 60)
        logger.info("SYNC OPERATION COMPLETED SUCCESSFULLY")
        logger.info(f"Total execution time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)")
        logger.info("=" * 60)
        
    except Exception as e:
        end_time = time.time()
        total_time = end_time - start_time
        print(f"‚ùå Sync failed: {str(e)}")
        
        logger.error("=" * 60)
        logger.error("SYNC OPERATION FAILED")
        logger.error(f"Error: {str(e)}")
        logger.error(f"Execution time before failure: {total_time:.2f} seconds")
        logger.error("=" * 60)
        raise
