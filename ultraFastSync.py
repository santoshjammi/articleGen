#!/usr/bin/env python3
"""
Ultra-Fast FTP Sync - No verification, maximum performance
Use this when you're confident about the remote directory structure
"""

import os
import ftplib
import concurrent.futures
import json
import time
import logging
from datetime import datetime
from tqdm import tqdm
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Setup logging - FILE ONLY for maximum performance
log_dir = "logs"
os.makedirs(log_dir, exist_ok=True)
log_filename = f"{log_dir}/ultraFastSync_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_filename)
        # No console output for maximum speed
    ]
)
logger = logging.getLogger(__name__)

FTP_HOST = os.getenv("FTP_HOST")
FTP_USER = os.getenv("FTP_USER")
FTP_PASS = os.getenv("FTP_PASS")
LOCAL_DIRECTORY = os.getenv("LOCAL_DIRECTORY")
REMOTE_DIRECTORY = os.getenv("REMOTE_DIRECTORY")
MAX_WORKERS = int(os.getenv("MAX_WORKERS", 20))  # High performance default

MANIFEST_FILE_PATH = os.path.join(LOCAL_DIRECTORY, ".sync_manifest.json")
DIFFERENTIAL_MANIFEST_PATH = os.path.join(LOCAL_DIRECTORY, ".differential_sync.json")

def quick_verify(remote_dir, ftp_credentials):
    """Quick verification - just check if we can connect and access the directory"""
    host, user, password = ftp_credentials
    try:
        logger.info(f"üîç Verifying connection to {host}...")
        with ftplib.FTP(host) as ftp:
            ftp.login(user=user, passwd=password)
            ftp.cwd(remote_dir)
            logger.info(f"‚úÖ Connected to: {remote_dir}")
            return True
    except Exception as e:
        logger.error(f"‚ùå Connection failed: {e}")
        return False

def load_differential_manifest():
    """Load differential manifest generated by auto_publish.sh Step 2.5"""
    logger.info("Loading differential manifest for smart sync...")
    if os.path.exists(DIFFERENTIAL_MANIFEST_PATH):
        with open(DIFFERENTIAL_MANIFEST_PATH, 'r') as f:
            try:
                diff_manifest = json.load(f)
                summary = diff_manifest.get('summary', {})
                logger.info(f"Differential manifest loaded: {summary.get('files_to_upload', 0)} files to upload")
                return diff_manifest
            except json.JSONDecodeError:
                logger.warning("Differential manifest corrupted, falling back to full scan")
                return None
    logger.warning("No differential manifest found, falling back to full scan")
    return None

def load_manifest():
    """Load manifest generated by auto_publish.sh (silently)"""
    logger.info("Loading sync manifest generated by auto_publish.sh...")
    if os.path.exists(MANIFEST_FILE_PATH):
        with open(MANIFEST_FILE_PATH, 'r') as f:
            try:
                manifest = json.load(f)
                logger.info(f"Manifest loaded with {len(manifest)} entries")
                return manifest
            except json.JSONDecodeError:
                logger.warning("Manifest file corrupted, starting fresh")
                return {}
    logger.warning("No manifest found. Please ensure auto_publish.sh has run generateLocalManifest.py first.")
    return {}

def create_directories_smart(directories_to_create, ftp_credentials):
    """Smart directory creation - only create directories that don't exist"""
    if not directories_to_create:
        return
    
    host, user, password = ftp_credentials
    directories_created = 0
    directories_checked = len(directories_to_create)
    
    logger.info("Smart directory creation starting...")
    start_time = time.time()
    
    try:
        with ftplib.FTP(host) as ftp:
            ftp.login(user=user, passwd=password)
            
            for directory in sorted(directories_to_create):
                try:
                    # Try to change to the directory to check if it exists
                    current_dir = ftp.pwd()
                    ftp.cwd(directory)
                    ftp.cwd(current_dir)  # Return to original directory
                    # If we get here, directory exists - skip creation
                    logger.debug(f"üìÇ Directory exists, skipped: {directory}")
                except ftplib.error_perm:
                    # Directory doesn't exist, create it
                    try:
                        ftp.mkd(directory)
                        directories_created += 1
                        logger.info(f"‚úÖ Created new directory: {directory}")
                    except ftplib.error_perm:
                        # Might be a permission issue or already created by another thread
                        logger.debug(f"‚ö†Ô∏è Could not create directory: {directory}")
                        pass
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Directory creation error: {e}")
    
    creation_time = time.time() - start_time
    directories_skipped = directories_checked - directories_created
    
    logger.info(f"‚úÖ Smart directory creation completed in {creation_time:.2f} seconds")
    logger.info(f"   üìÇ Directories checked: {directories_checked}")
    logger.info(f"   üÜï New directories created: {directories_created}")
    logger.info(f"   ‚úÖ Existing directories skipped: {directories_skipped}")

def upload_file(local_path, remote_path, ftp_credentials):
    """Ultra-fast upload function with manifest tracking"""
    host, user, password = ftp_credentials
    try:
        with ftplib.FTP(host) as ftp:
            ftp.login(user=user, passwd=password)
            with open(local_path, 'rb') as file:
                ftp.storbinary(f'STOR {remote_path}', file)
            return True, os.path.getsize(local_path)
    except Exception:
        return False, 0

def update_manifest(uploaded_files):
    """Update manifest with uploaded files (with logging)"""
    if not uploaded_files:
        return
        
    logger.info(f"Updating manifest with {len(uploaded_files)} files...")
    manifest = load_manifest()
    for remote_path, file_size in uploaded_files.items():
        manifest[remote_path] = file_size
    
    try:
        with open(MANIFEST_FILE_PATH, 'w') as f:
            json.dump(manifest, f, indent=2)
        logger.info(f"‚úÖ Manifest updated: {len(uploaded_files)} files")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Could not update manifest: {e}")

def differential_sync():
    """Ultra-fast differential sync using pre-generated change analysis"""
    sync_start = time.time()
    logger.info("Starting ultra-fast differential sync process...")
    
    if not all([FTP_HOST, FTP_USER, FTP_PASS, LOCAL_DIRECTORY, REMOTE_DIRECTORY]):
        logger.error("‚ùå Missing environment variables")
        return False

    logger.info("‚ö° ULTRA-FAST DIFFERENTIAL SYNC MODE")
    logger.info("=" * 40)
    
    # Quick verification first
    verify_start = time.time()
    ftp_credentials = (FTP_HOST, FTP_USER, FTP_PASS)
    if not quick_verify(REMOTE_DIRECTORY, ftp_credentials):
        logger.error("‚ùå Verification failed. Sync aborted.")
        return False
    verify_time = time.time() - verify_start
    logger.info(f"‚úÖ Verification completed in {verify_time:.2f} seconds")
    
    # Load differential manifest
    diff_manifest = load_differential_manifest()
    if not diff_manifest:
        logger.warning("Falling back to traditional sync method...")
        return fast_sync()
    
    # Extract files to upload from differential analysis
    files_to_upload = []
    directories_to_create = set(diff_manifest.get('new_directories', []))
    
    # Add new files
    for file_info in diff_manifest.get('new_files', []):
        files_to_upload.append((file_info['local_path'], file_info['remote_path']))
    
    # Add changed files  
    for file_info in diff_manifest.get('changed_files', []):
        files_to_upload.append((file_info['local_path'], file_info['remote_path']))
    
    summary = diff_manifest.get('summary', {})
    logger.info(f"üìä Differential analysis results:")
    logger.info(f"   üÜï New files: {summary.get('new_files', 0)}")
    logger.info(f"   üîÑ Changed files: {summary.get('changed_files', 0)}")
    logger.info(f"   ‚úÖ Unchanged files: {summary.get('unchanged_files', 0)}")
    logger.info(f"   üìÇ Directories: {len(directories_to_create)}")
    logger.info(f"   ‚ö° Total to upload: {len(files_to_upload)}")
    
    if len(files_to_upload) == 0:
        logger.info("üéâ No changes detected - sync completed instantly!")
        print("üéâ No changes detected - sync completed instantly!")
        return True
    
    # Create directories smartly (only those that don't exist)
    if directories_to_create:
        dir_start = time.time()
        logger.info(f"Checking {len(directories_to_create)} directories...")
        create_directories_smart(directories_to_create, ftp_credentials)
        dir_time = time.time() - dir_start
        logger.info(f"‚úÖ Smart directory creation completed in {dir_time:.2f} seconds")
    
    logger.info(f"üöÄ Starting differential upload with {MAX_WORKERS} workers...")
    upload_start = time.time()
    
    # Ultra-fast parallel upload of changes only
    ftp_credentials = (FTP_HOST, FTP_USER, FTP_PASS)
    successful = 0
    failed = 0
    uploaded_files = {}
    total_bytes = 0
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_file = {
            executor.submit(upload_file, local_path, remote_path, ftp_credentials): (local_path, remote_path)
            for local_path, remote_path in files_to_upload
        }

        # Minimal console output for maximum speed
        print(f"‚ö° Uploading {len(files_to_upload)} changed files...")
        for future in concurrent.futures.as_completed(future_to_file):
            local_path, remote_path = future_to_file[future]
            success, file_size = future.result()
            if success:
                successful += 1
                uploaded_files[remote_path] = file_size
                total_bytes += file_size
                logger.debug(f"‚úÖ Uploaded: {os.path.basename(remote_path)} ({file_size} bytes)")
            else:
                failed += 1
                logger.warning(f"‚ùå Failed: {os.path.basename(remote_path)}")

    upload_time = time.time() - upload_start
    sync_time = time.time() - sync_start
    
    # Single console summary
    print(f"‚ö° Differential sync complete: {successful} success, {failed} failed ({upload_time:.1f}s)")
    
    # Log comprehensive results to file only
    logger.info("=" * 60)
    logger.info("DIFFERENTIAL SYNC SUMMARY")
    logger.info("=" * 60)
    logger.info(f"üìä Files processed: {len(files_to_upload)}")
    logger.info(f"‚úÖ Successful uploads: {successful}")
    logger.info(f"‚ùå Failed uploads: {failed}")
    logger.info(f"üìà Total data uploaded: {total_bytes:,} bytes ({total_bytes/1024/1024:.2f} MB)")
    logger.info(f"‚è±Ô∏è Upload time: {upload_time:.2f} seconds")
    logger.info(f"‚ö° Upload speed: {(total_bytes/upload_time/1024/1024):.2f} MB/s" if upload_time > 0 else "N/A")
    logger.info(f"üïí Total sync time: {sync_time:.2f} seconds")
    
    # Update manifest with successful uploads
    if uploaded_files:
        manifest_update_start = time.time()
        update_manifest(uploaded_files)
        manifest_update_time = time.time() - manifest_update_start
        logger.info(f"üìù Manifest updated in {manifest_update_time:.2f} seconds")
    
    return True

def fast_sync():
    """Ultra-fast sync with quick verification"""
    sync_start = time.time()
    logger.info("Starting ultra-fast sync process...")
    
    if not all([FTP_HOST, FTP_USER, FTP_PASS, LOCAL_DIRECTORY, REMOTE_DIRECTORY]):
        logger.error("‚ùå Missing environment variables")
        return

    logger.info("üöÄ ULTRA-FAST SYNC MODE")
    logger.info("=" * 30)
    
    # Quick verification first
    verify_start = time.time()
    ftp_credentials = (FTP_HOST, FTP_USER, FTP_PASS)
    if not quick_verify(REMOTE_DIRECTORY, ftp_credentials):
        logger.error("‚ùå Verification failed. Sync aborted.")
        return
    verify_time = time.time() - verify_start
    logger.info(f"‚úÖ Quick verification completed in {verify_time:.2f} seconds")
    
    # Load manifest
    manifest_start = time.time()
    remote_files = load_manifest()
    manifest_time = time.time() - manifest_start
    logger.info(f"Manifest processing completed in {manifest_time:.2f} seconds")
    
    files_to_upload = []
    directories_to_create = set()
    
    # Collect files and directories
    for root, dirs, files in os.walk(LOCAL_DIRECTORY):
        for dir_name in dirs:
            local_subdir = os.path.join(root, dir_name)
            remote_subdir = os.path.join(REMOTE_DIRECTORY, os.path.relpath(local_subdir, LOCAL_DIRECTORY)).replace("\\", "/")
            directories_to_create.add(remote_subdir)

        for file_name in files:
            local_path = os.path.join(root, file_name)
            relative_path = os.path.relpath(local_path, LOCAL_DIRECTORY)
            remote_path = os.path.join(REMOTE_DIRECTORY, relative_path).replace("\\", "/")
            local_size = os.path.getsize(local_path)
            
            if remote_path not in remote_files or remote_files[remote_path] != local_size:
                files_to_upload.append((local_path, remote_path))
    
    logger.info(f"üìÅ Found {len(directories_to_create)} directories to create")
    logger.info(f"üìÑ Found {len(files_to_upload)} files to upload")
    
    # Create directories smartly (only those that don't exist)
    if directories_to_create:
        dir_start = time.time()
        logger.info(f"Checking {len(directories_to_create)} directories...")
        create_directories_smart(directories_to_create, ftp_credentials)
        dir_time = time.time() - dir_start
        logger.info(f"‚úÖ Smart directory creation completed in {dir_time:.2f} seconds")
    
    if not files_to_upload:
        logger.info("‚úÖ No files to upload - everything is up to date!")
        return
    
    logger.info(f"ÔøΩ Starting ultra-fast upload with {MAX_WORKERS} workers...")
    upload_start = time.time()
    
    # Ultra-fast parallel upload
    ftp_credentials = (FTP_HOST, FTP_USER, FTP_PASS)
    successful = 0
    failed = 0
    uploaded_files = {}  # Track for manifest update
    total_bytes = 0
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_file = {
            executor.submit(upload_file, local_path, remote_path, ftp_credentials): (local_path, remote_path)
            for local_path, remote_path in files_to_upload
        }

        for future in tqdm(concurrent.futures.as_completed(future_to_file), 
                          total=len(files_to_upload),
                          desc="Upload",
                          ncols=60):
            local_path, remote_path = future_to_file[future]
            success, file_size = future.result()
            if success:
                successful += 1
                uploaded_files[remote_path] = file_size
                total_bytes += file_size
                logger.debug(f"‚úÖ Uploaded: {os.path.basename(remote_path)} ({file_size} bytes)")
            else:
                failed += 1
                logger.warning(f"‚ùå Failed: {os.path.basename(remote_path)}")

    upload_time = time.time() - upload_start
    sync_time = time.time() - sync_start
    
    # Log comprehensive results
    logger.info("=" * 60)
    logger.info("ULTRA-FAST UPLOAD SUMMARY")
    logger.info("=" * 60)
    logger.info(f"üìä Files processed: {len(files_to_upload)}")
    logger.info(f"‚úÖ Successful uploads: {successful}")
    logger.info(f"‚ùå Failed uploads: {failed}")
    logger.info(f"üìà Total data uploaded: {total_bytes:,} bytes ({total_bytes/1024/1024:.2f} MB)")
    logger.info(f"‚è±Ô∏è Upload time: {upload_time:.2f} seconds")
    logger.info(f"‚ö° Upload speed: {(total_bytes/upload_time/1024/1024):.2f} MB/s" if upload_time > 0 else "N/A")
    logger.info(f"üïí Total sync time: {sync_time:.2f} seconds")
    
    # Update manifest with successful uploads
    if uploaded_files:
        manifest_update_start = time.time()
        update_manifest(uploaded_files)
        manifest_update_time = time.time() - manifest_update_start
        logger.info(f"üìù Manifest updated in {manifest_update_time:.2f} seconds")
    
    # Update manifest with successful uploads
    if uploaded_files:
        update_manifest(uploaded_files)

if __name__ == "__main__":
    start_time = time.time()
    print(f"‚ö° Ultra-Fast Sync (uses manifest from auto_publish.sh) - Log: {log_filename}")
    
    logger.info("=" * 60)
    logger.info("Starting Ultra-Fast FTP Sync Operation")
    logger.info("=" * 60)
    logger.info("NOTE: Using manifest generated by auto_publish.sh Step 0")
    logger.info(f"Log file: {log_filename}")
    logger.info(f"Local Directory: {LOCAL_DIRECTORY}")
    logger.info(f"Remote Directory: {REMOTE_DIRECTORY}")
    logger.info(f"Max Workers: {MAX_WORKERS}")
    logger.info(f"FTP Host: {FTP_HOST}")
    
    try:
        # Try differential sync first, fallback to fast_sync if needed
        success = differential_sync()
        
        end_time = time.time()
        total_time = end_time - start_time
        if success:
            print(f"‚ö° Ultra-fast differential sync completed in {total_time:.1f}s")
        else:
            print(f"‚ö° Sync completed with fallback method in {total_time:.1f}s")
        
        logger.info("=" * 60)
        logger.info("ULTRA-FAST SYNC COMPLETED SUCCESSFULLY")
        logger.info(f"Total execution time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)")
        logger.info("=" * 60)
        
    except Exception as e:
        end_time = time.time()
        total_time = end_time - start_time
        print(f"‚ùå Ultra-fast sync failed: {str(e)}")
        
        logger.error("=" * 60)
        logger.error("ULTRA-FAST SYNC FAILED")
        logger.error(f"Error: {str(e)}")
        logger.error(f"Execution time before failure: {total_time:.2f} seconds")
        logger.error("=" * 60)
        raise
